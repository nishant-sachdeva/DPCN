{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52d88a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"MPROC_DPCN_PROJECT_PART1.ipynb\n",
    "\n",
    "Automatically generated by Colaboratory.\n",
    "\n",
    "Original file is located at\n",
    "    https://colab.research.google.com/drive/1fFWimNIb1JfG344XjnqlM8N-m2zfwFY-\n",
    "\n",
    "Here are the steps we are looking to implement.\n",
    "\n",
    "1. Get the Math overflow data, present it, and see what it looks like\n",
    "    - We assume that it will contain A, B, timestamp. \n",
    "    - Verify the same\n",
    "\n",
    "2. Break it into 20 or so sets, by time.\n",
    "\n",
    "3. Plot static graphs for these 20 sets.\n",
    "\n",
    "4. Simulate attacks on these static graphs.\n",
    "    - We want 3 graphs, for three different stages of the attack\n",
    "    - Beginning of the attack, some point in the middle, and then when the critical fraction is reached.\n",
    "\n",
    "5. Collect these three graphs and send them on forward to get to the next stage.\n",
    "\n",
    "# New Section\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocessing\n",
    "\n",
    "\n",
    "class createGraphs:\n",
    "    def __init__(self, mathoverFlowDataPath, numPartitions, attackFraction, attackFractionMax, attackFunction, store_directory):\n",
    "        self.mathoverFlowDataPath = mathoverFlowDataPath\n",
    "        self.numPartitions = numPartitions\n",
    "        self.attackFraction = attackFraction\n",
    "        self.attackFractionMax = attackFractionMax\n",
    "        self.attackFunction = attackFunction\n",
    "        self.directory_name = store_directory\n",
    "        self.result_graphs = []\n",
    "\n",
    "\n",
    "    # Read the math overflow data\n",
    "    # it should contain 3 columns, nodeA, nodeB, timestamp\n",
    "    def read_data_into_graphs(self):\n",
    "        df = pd.read_csv(\n",
    "            self.mathoverFlowDataPath, sep=\" \", names=[\"A\", \"B\", \"timestamp\"]\n",
    "        ).sort_values(by=['timestamp'])\n",
    "\n",
    "        # calculate the partition size\n",
    "        partition_size = len(df) // self.numPartitions\n",
    "\n",
    "        # divide the data into partitions\n",
    "        partitions = [\n",
    "            df.iloc[:(i*partition_size)] for i in range(1, self.numPartitions+1)\n",
    "        ]\n",
    "        \n",
    "        # graphs = [\n",
    "        #     (lambda x, p: x.add_edges_from(zip(p['A'], p['B']), timestamp=p['timestamp']))(nx.DiGraph, p) for p in partitions\n",
    "        # ]\n",
    "\n",
    "        graphs = []\n",
    "        for p in partitions:\n",
    "            G = nx.DiGraph()\n",
    "            G.add_edges_from(zip(p['A'], p['B']), timestamp=p['timestamp'])\n",
    "            graphs.append(G)\n",
    "\n",
    "        return graphs\n",
    "\n",
    "\n",
    "    def conduct_attack(self, graph):\n",
    "        print(\"Conducting Attack\")\n",
    "        def attack(graph, attack_fraction):\n",
    "            nodes_by_degree = sorted(graph.nodes(), key=lambda x: graph.out_degree[x], reverse=True)\n",
    "            num_nodes_to_remove = int(attack_fraction * graph.number_of_nodes())\n",
    "            nodes_to_remove = nodes_by_degree[:num_nodes_to_remove]\n",
    "            graph.remove_nodes_from(nodes_to_remove)\n",
    "            return graph\n",
    "\n",
    "        def failure(graph, attack_fraction):\n",
    "            # do nothing\n",
    "            num_nodes_to_remove = int(attack_fraction * graph.number_of_nodes())\n",
    "            nodes_remove = np.random.choice(graph.nodes(), size = num_nodes_to_remove, replace = False)\n",
    "            graph.remove_nodes_from(nodes_remove)\n",
    "            return graph\n",
    "\n",
    "        def simulate_attack(graph, attack_fraction, attack_fraction_max, attack_function):\n",
    "            attack_so_far = 0\n",
    "            captured_graphs = []\n",
    "\n",
    "            while attack_so_far < attack_fraction_max:\n",
    "                # plot the appropriate data points for the current graph\n",
    "                # capture_graph_data(graph)\n",
    "                if attack_function == \"attack\":\n",
    "                    graph = attack(graph, attack_fraction)\n",
    "                elif attack_function == \"failure\":\n",
    "                    graph = failure(graph, attack_fraction)\n",
    "                \n",
    "                captured_graphs.append(graph.copy())\n",
    "                attack_so_far += attack_fraction\n",
    "\n",
    "            return captured_graphs\n",
    "    \n",
    "        return simulate_attack(\n",
    "            graph, \n",
    "            self.attackFraction, \n",
    "            self.attackFractionMax,\n",
    "            self.attackFunction\n",
    "        )\n",
    "\n",
    "    def generate_graphs(self):\n",
    "        pool = multiprocessing.Pool()\n",
    "        pool = multiprocessing.Pool(processes=self.numPartitions)\n",
    "        inputs = self.read_data_into_graphs()\n",
    "        self.result_graphs = pool.map(self.conduct_attack, inputs)\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "        print(\"Created Graphs\")\n",
    "\n",
    "    def store_graph_into_file(self, marked_graph):\n",
    "        (graph_set_id, graph_id, graph) = marked_graph\n",
    "        folder_name = \"set\" + str(graph_set_id)\n",
    "        file_name = \"graph\" + str(graph_id) + \".txt\"\n",
    "        file_path = self.directory_name + folder_name + '/' + file_name\n",
    "        # print(file_path)\n",
    "\n",
    "        with open(file_path, 'w') as f:\n",
    "            for edge in graph.edges(data=True):\n",
    "                nodeA, nodeB, timestamp = edge[0], edge[1], edge[2]['timestamp']\n",
    "                # print(nodeA, nodeB, timestamp)\n",
    "                f.write(f\"{nodeA} {nodeB} {timestamp}\\n\")\n",
    "    \n",
    "    def store_graph_set(self, marked_graph_set):\n",
    "        (i, graph_set) = marked_graph_set\n",
    "\n",
    "        folder_name = \"set\" + str(i)\n",
    "\n",
    "        dir_path = self.directory_name + folder_name\n",
    "        if not os.path.exists(dir_path):\n",
    "            os.makedirs(dir_path)\n",
    "        \n",
    "        print(\"storage starting for folder\", dir_path)\n",
    "        input = [(i, j, graph) for (j, graph) in zip([i for i in range(len(graph_set))], graph_set)]\n",
    "\n",
    "        for marked_graph in input:\n",
    "            self.store_graph_into_file(marked_graph)\n",
    "        \n",
    "        print(\"storage done for folder\", dir_path)\n",
    "        return 1\n",
    "\n",
    "    def store_graphs(self):\n",
    "        pool = multiprocessing.Pool()\n",
    "        pool = multiprocessing.Pool(processes=self.numPartitions)\n",
    "        input = zip([i for i in range(len(self.result_graphs))], self.result_graphs)\n",
    "\n",
    "        _stored_graphs = pool.map(self.store_graph_set, input)\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "        print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44ef52cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_name = 'dpcn_result_graphs_attack/'\n",
    "\n",
    "def store_graph_into_file(marked_graph):\n",
    "    (graph_set_id, graph_id, graph) = marked_graph\n",
    "    folder_name = \"set\" + str(graph_set_id)\n",
    "    file_name = \"graph\" + str(graph_id) + \".txt\"\n",
    "    file_path = directory_name + folder_name + '/' + file_name\n",
    "    # print(file_path)\n",
    "\n",
    "    with open(file_path, 'w') as f:\n",
    "        for edge in graph.edges(data=True):\n",
    "            nodeA, nodeB, timestamp = edge[0], edge[1], edge[2]['timestamp']\n",
    "            # print(nodeA, nodeB, timestamp)\n",
    "            f.write(f\"{nodeA} {nodeB} {timestamp}\\n\")\n",
    "\n",
    "\n",
    "def graphset_storage_function(marked_graph_set):\n",
    "    (i, graph_set) = marked_graph_set\n",
    "\n",
    "    folder_name = \"set\" + str(i)\n",
    "\n",
    "    dir_path = directory_name + folder_name\n",
    "    if not os.path.exists(dir_path):\n",
    "        os.makedirs(dir_path)\n",
    "    \n",
    "    print(\"storage starting for folder\", dir_path)\n",
    "    input = [(i, j, graph) for (j, graph) in zip([i for i in range(len(graph_set))], graph_set)]\n",
    "\n",
    "    for marked_graph in input:\n",
    "        store_graph_into_file(marked_graph)\n",
    "    \n",
    "    print(\"storage done for folder\", dir_path)\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fd29cd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conducting Attack\n",
      "Conducting Attack\n",
      "Conducting Attack\n",
      "Conducting Attack\n",
      "Conducting Attack\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'nodes_by4_degree' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n    result = (True, func(*args, **kwds))\n  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 48, in mapstar\n    return list(map(*args))\n  File \"/tmp/ipykernel_24563/4217714891.py\", line 108, in conduct_attack\n    return simulate_attack(\n  File \"/tmp/ipykernel_24563/4217714891.py\", line 99, in simulate_attack\n    graph = attack(graph, attack_fraction)\n  File \"/tmp/ipykernel_24563/4217714891.py\", line 80, in attack\n    nodes_to_remove = nodes_by4_degree[:num_nodes_to_remove]\nNameError: name 'nodes_by4_degree' is not defined\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 9\u001b[0m\n\u001b[1;32m      1\u001b[0m graphSet \u001b[38;5;241m=\u001b[39m createGraphs(\n\u001b[1;32m      2\u001b[0m     mathoverFlowDataPath \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msx-mathoverflow-a2q.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      3\u001b[0m     numPartitions \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      7\u001b[0m     store_directory \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdpcn_result_graphs_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattack\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      8\u001b[0m )\n\u001b[0;32m----> 9\u001b[0m \u001b[43mgraphSet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_graphs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 119\u001b[0m, in \u001b[0;36mcreateGraphs.generate_graphs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    117\u001b[0m pool \u001b[38;5;241m=\u001b[39m multiprocessing\u001b[38;5;241m.\u001b[39mPool(processes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnumPartitions)\n\u001b[1;32m    118\u001b[0m inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread_data_into_graphs()\n\u001b[0;32m--> 119\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresult_graphs \u001b[38;5;241m=\u001b[39m \u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconduct_attack\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m pool\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m    121\u001b[0m pool\u001b[38;5;241m.\u001b[39mjoin()\n",
      "File \u001b[0;32m/usr/lib/python3.8/multiprocessing/pool.py:364\u001b[0m, in \u001b[0;36mPool.map\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmap\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, iterable, chunksize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    360\u001b[0m     \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;124;03m    Apply `func` to each element in `iterable`, collecting the results\u001b[39;00m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;124;03m    in a list that is returned.\u001b[39;00m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m--> 364\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapstar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.8/multiprocessing/pool.py:771\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    769\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n\u001b[1;32m    770\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 771\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nodes_by4_degree' is not defined"
     ]
    }
   ],
   "source": [
    "graphSet = createGraphs(\n",
    "    mathoverFlowDataPath = \"sx-mathoverflow-a2q.txt\",\n",
    "    numPartitions = 5,\n",
    "    attackFraction = 0.005,\n",
    "    attackFractionMax = 0.4,\n",
    "    attackFunction = \"attack\",\n",
    "    store_directory = 'dpcn_result_graphs_' + \"attack\" + '/'\n",
    ")\n",
    "graphSet.generate_graphs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2e7cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_graph_set = graphSet.result_graphs[0]\n",
    "graphset_storage_function((0, relevant_graph_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c50d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_graph_set = graphSet.result_graphs[1]\n",
    "graphset_storage_function((1, relevant_graph_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e98399e",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_graph_set = graphSet.result_graphs[2]   \n",
    "graphset_storage_function((2, relevant_graph_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231b0112",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_graph_set = graphSet.result_graphs[3]\n",
    "graphset_storage_function((3, relevant_graph_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9775f26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_graph_set = graphSet.result_graphs[4]\n",
    "graphset_storage_function((4, relevant_graph_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1b4fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "graphSet = createGraphs(\n",
    "    mathoverFlowDataPath = \"sx-mathoverflow-a2q.txt\",\n",
    "    numPartitions = 5,\n",
    "    attackFraction = 0.001,\n",
    "    attackFractionMax = 0.4,\n",
    "    attackFunction = \"attack\",\n",
    "    store_directory = 'dpcn_result_graphs_' + \"attack\" + '/'\n",
    ")\n",
    "graphSet.generate_graphs()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
